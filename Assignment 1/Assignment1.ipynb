{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  IN3050/IN4050 Mandatory Assignment 1: Traveling Salesman Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "Before you begin the exercise, review the rules at this website:\n",
    "https://www.uio.no/english/studies/examinations/compulsory-activities/mn-ifi-mandatory.html\n",
    "(This is an individual assignment. You are not allowed to deliver together or copy/share source-code/answers\n",
    "with others.)\n",
    "\n",
    "## Delivering\n",
    "**Deadline**: *Friday, February 21, 2020*\n",
    "\n",
    "## What to deliver?\n",
    "Deliver one single zipped folder (.zip, .tgz or .tar.gz) which includes:\n",
    "* PDF report containing:\n",
    "    * Your name and username (!)\n",
    "    * Instructions on how to run your program.\n",
    "    * Answers to all questions from assignment.\n",
    "    * Brief explanation of what you’ve done.\n",
    "    * *Your PDF may be generated by exporting your Jupyter Notebook to PDF, if you have answered all questions in your notebook*\n",
    "* Source code\n",
    "    * Source code may be delivered as jupyter notebooks or python files (.py)\n",
    "* The european cities file so the program will run right away.\n",
    "* Any files needed for the group teacher to easily run your program on IFI linux machines.\n",
    "\n",
    "**Important**: if you weren’t able to finish the assignment, use the PDF report to elaborate on what you’ve tried\n",
    "and what problems you encountered. Students who have made an effort and attempted all parts of the assignment\n",
    "will get a second chance even if they fail initially. This exercise will be graded PASS/FAIL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this exercise, you will attempt to solve an instance of the traveling salesman problem (TSP) using different\n",
    "methods. The goal is to become familiar with evolutionary algorithms and to appreciate their effectiveness on a\n",
    "difficult search problem. You may use whichever programming language you like, but we strongly suggest that\n",
    "you try to use Python, since you will be required to write the second assignment in Python. You must write\n",
    "your program from scratch (but you may use non-EA-related libraries).\n",
    "\n",
    "\n",
    "|  &nbsp;   | Barcelona | Belgrade |  Berlin | Brussels | Bucharest | Budapest |\n",
    "|:---------:|:---------:|:--------:|:-------:|:--------:|:---------:|:--------:|\n",
    "| Barcelona |     0     |  1528.13 | 1497.61 |  1062.89 |  1968.42  |  1498.79 |\n",
    "|  Belgrade |  1528.13  |     0    |  999.25 |  1372.59 |   447.34  |  316.41  |\n",
    "|   Berlin  |  1497.61  |  999.25  |    0    |  651.62  |  1293.40  |  1293.40 |\n",
    "|  Brussels |  1062.89  |  1372.59 |  651.62 |     0    |  1769.69  |  1131.52 |\n",
    "| Bucharest |  1968.42  |  447.34  | 1293.40 |  1769.69 |     0     |  639.77  |\n",
    "|  Budapest |  1498.79  |  316.41  | 1293.40 |  1131.52 |   639.77  |     0    |\n",
    "\n",
    "\n",
    "<center>Figure 1: First 6 cities from csv file.</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "The traveling salesman, wishing to disturb the residents of the major cities in some region of the world in\n",
    "the shortest time possible, is faced with the problem of finding the shortest tour among the cities. A tour\n",
    "is a path that starts in one city, visits all of the other cities, and then returns to the starting point. The\n",
    "relevant pieces of information, then, are the cities and the distances between them. In this instance of the\n",
    "TSP, a number of European cities are to be visited. Their relative distances are given in the data file, *european_cities.csv*, found in the zip file with the mandatory assignment.\n",
    "\n",
    "(You will use permutations to represent tours in your programs. If you use Python, the **itertools** module provides\n",
    "a permutations function that returns successive permutations, this is useful for exhaustive search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhaustive Search\n",
    "First, try to solve the problem by inspecting every possible tour. Start by writing a program to find the shortest\n",
    "tour among a subset of the cities (say, **6** of them). Measure the amount of time your program takes. Incrementally\n",
    "add more cities and observe how the time increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V = 6: 5018.8099999999995\n",
      "0.002257108688354492 seconds\n",
      "\n",
      "\n",
      "V = 7: 5487.889999999999\n",
      "0.014030933380126953 seconds\n",
      "\n",
      "\n",
      "V = 8: 6667.489999999999\n",
      "0.056568145751953125 seconds\n",
      "\n",
      "\n",
      "V = 9: 6678.549999999999\n",
      "0.5182459354400635 seconds\n",
      "\n",
      "\n",
      "V = 10: 7486.309999999999\n",
      "6.0101377964019775 seconds\n",
      "Actual sequence:  (6, 8, 3, 7, 0, 1, 9, 4, 5, 2) and back to start (6)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTO FIND THE SHORTEST PATH OF 11 CITIES WILL TAKE APROX 1MIN!\\nThis is why the code is inside a docstring\\n\\nV = 11\\ngraph = read()\\n#index_list = [x for x in range(V)]\\n#print(index_list)\\nstart_time = time.time()\\nmin_length, min_perm = exhaustive()\\nprint(f\"V = {V}:\", min_length)\\nprint(f\"{(time.time() - start_time)} seconds\")\\nprint(\"Actual sequence: \", min_perm)\\nprint(\"\\n\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement the algorithm here\n",
    "from sys import maxsize\n",
    "import time \n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "def read():\n",
    "    \"\"\"\n",
    "    Reads the 'european_cities.csv'-file, using the ';' as delimiter \n",
    "    and returns a graph representing the cities.\n",
    "    \n",
    "    The graph is a list containing a list of each cities distance to each other.\n",
    "    The number of cities read by the function is based on the value of the\n",
    "    variable V.\n",
    "    \n",
    "        returns:\n",
    "                graph(list:list:float): Contains lists that represents each city and its distance to each other.\n",
    "    \"\"\"\n",
    "    graph = []\n",
    "    with open('european_cities.csv') as file:\n",
    "        reader = csv.reader(file, delimiter =';')\n",
    "        counter = 0\n",
    "        for row in reader:\n",
    "            if counter > 0:\n",
    "                graph.append(list(map(float, [row[x] for x in range(V)])))\n",
    "            counter += 1\n",
    "            if counter == V+1:\n",
    "                break\n",
    "    return graph\n",
    "\n",
    "def exhaustive():\n",
    "    \"\"\"\n",
    "    Finds all the permutations available from V, and finds the one with the shortest path.\n",
    "    \n",
    "    Using maxsize as a starting point for the min_length variable.\n",
    "    Creates a list from 0 to V as a starting permutation. Then using \n",
    "    itertools.permutations to give us all the possible permutations.\n",
    "    We then check each permutation for its length based on the order \n",
    "    in the list given. At the end we add a last step from the last node \n",
    "    back to the first to fulfill each criteria of the TSP.\n",
    "    \n",
    "    A possible upgrade to this function to reduce time would be to 'skip' \n",
    "    all permutations that 'shifts' the first node around, since the pick \n",
    "    of a starting point does not really matter. But since this task explicitly \n",
    "    tell us to 'try to solve the problem by inspecting every possible tour', \n",
    "    this has not been skipped.\n",
    "    \n",
    "        returns:\n",
    "            min_length(float): minimal length of all paths found.\n",
    "            min_perm(list:int): the actual path that gives the minimal length.\n",
    "    \"\"\"\n",
    "    min_length = maxsize\n",
    "    min_perm = []\n",
    "    index_list = [x for x in range(V)]\n",
    "    for perm in itertools.permutations(index_list):\n",
    "        temp_length = 0\n",
    "        for x in range(V-1):\n",
    "            temp_length += graph[perm[x]][perm[x+1]]\n",
    "        temp_length += graph[perm[V-1]][perm[0]]\n",
    "        if min_length > temp_length:\n",
    "            min_length = temp_length\n",
    "            min_perm = perm\n",
    "            \n",
    "    return min_length, min_perm\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Here's some prints to show the different results using the \n",
    "exhaustive search on the first 6-10 cities. Using time.time() \n",
    "to track the time usage of the function 'exhaustive()' for \n",
    "each V.\n",
    "\"\"\"\n",
    "V = 6\n",
    "graph = read()\n",
    "start_time = time.time()\n",
    "min_length, min_perm = exhaustive()\n",
    "print(f\"V = {V}:\", min_length)\n",
    "print(f\"{(time.time() - start_time)} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "V = 7\n",
    "graph = read()\n",
    "start_time = time.time()\n",
    "min_length, min_perm = exhaustive()\n",
    "print(f\"V = {V}:\", min_length)\n",
    "print(f\"{(time.time() - start_time)} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "V = 8\n",
    "graph = read()\n",
    "start_time = time.time()\n",
    "min_length, min_perm = exhaustive()\n",
    "print(f\"V = {V}:\", min_length)\n",
    "print(f\"{(time.time() - start_time)} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "V = 9\n",
    "graph = read()\n",
    "start_time = time.time()\n",
    "min_length, min_perm = exhaustive()\n",
    "print(f\"V = {V}:\", min_length)\n",
    "print(f\"{(time.time() - start_time)} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "V = 10\n",
    "graph = read()\n",
    "start_time = time.time()\n",
    "min_length, min_perm = exhaustive()\n",
    "print(f\"V = {V}:\", min_length)\n",
    "print(f\"{(time.time() - start_time)} seconds\")\n",
    "print(\"Actual sequence: \", min_perm, f'and back to start ({min_perm[0]})')\n",
    "print(\"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "TO FIND THE SHORTEST PATH OF 11 CITIES WILL TAKE APROX 1MIN!\n",
    "This is why the code is inside a docstring\n",
    "\n",
    "V = 11\n",
    "graph = read()\n",
    "#index_list = [x for x in range(V)]\n",
    "#print(index_list)\n",
    "start_time = time.time()\n",
    "min_length, min_perm = exhaustive()\n",
    "print(f\"V = {V}:\", min_length)\n",
    "print(f\"{(time.time() - start_time)} seconds\")\n",
    "print(\"Actual sequence: \", min_perm)\n",
    "print(\"\\n\")\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shortest tour (i.e., the actual sequence of cities, and its length) among the first 10 cities (that is,\n",
    "the cities starting with B,C,D,H and I)? How long did your program take to find it? Calculate an approximation of how long it would take to perform exhaustive search on all 24 cities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Copenhagen', 'Hamburg', 'Brussels', 'Dublin', 'Barcelona', 'Belgrade', 'Istanbul', 'Bucharest', 'Budapest', 'Berlin']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nShortest tour among first 10 cities in order:\\n\\n['Copenhagen', 'Hamburg', 'Brussels', 'Dublin', 'Barcelona', \\n    'Belgrade', 'Istanbul', 'Bucharest', 'Budapest', 'Berlin']\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer\n",
    "\"\"\"\n",
    "The actual sequence of cities for 10 cities is (6, 8, 3, 7, 0, 1, 9, 4, 5, 2), \n",
    "where each number represent the index from 0 to 9 from left to right.\n",
    "It took aprox 5.83 seconds to find the shortest tour among the first 10 cities.\n",
    "\n",
    "My prediction for how long it would take to perform exhaustive serach on all 24 cities \n",
    "will be based on the pattern shown after running from V = 6 to V = 10. As of writing \n",
    "my numbers, from running the code from above, are as follows:\n",
    "\n",
    "V = 6:  0.0019161701202392578 seconds\n",
    "V = 7:  0.007659196853637695 seconds\n",
    "V = 8:  0.0584108829498291 seconds\n",
    "V = 9:  0.5253582000732422 seconds\n",
    "V = 10: 5.957304000854492 seconds\n",
    "V = 11: 66.67615795135498 seconds\n",
    "\n",
    "\n",
    "It would look like that the time of execution takes 10 times longer for each city added to the calculations. \n",
    "Therefore my approximation would be something of:\n",
    "66*10^13 seconds to find the shortest tour with an exhaustive search on all 24 cities.\n",
    "This has to do with the V! (factorial) amount of permutations.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Only interested the first line because this is the line containing the city names.\n",
    "\"\"\"\n",
    "city_list = [] #Storing all cities from file\n",
    "#Loop breaks after first row is stored\n",
    "with open('european_cities.csv') as file:\n",
    "    reader = csv.reader(file, delimiter =';')\n",
    "    for row in reader:\n",
    "        city_list = row\n",
    "        break\n",
    "\n",
    "#Makes a new list with the right order of cities, and prints\n",
    "right_order_city_list = [city_list[x] for x in min_perm]\n",
    "print(right_order_city_list)\n",
    "\n",
    "\"\"\"\n",
    "Shortest tour among first 10 cities in order:\n",
    "\n",
    "['Copenhagen', 'Hamburg', 'Brussels', 'Dublin', 'Barcelona', \n",
    "    'Belgrade', 'Istanbul', 'Bucharest', 'Budapest', 'Berlin']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Climbing\n",
    "Then, write a simple hill climber to solve the TSP. How well does the hill climber perform, compared to the result from the exhaustive search for the first **10 cities**? Since you are dealing with a stochastic algorithm, you\n",
    "should run the algorithm several times to measure its performance. Report the length of the tour of the best,\n",
    "worst and mean of 20 runs (with random starting tours), as well as the standard deviation of the runs, both with the **10 first cities**, and with all **24 cities**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of exhaustive search and hill climbing for the first 10 cities:\n",
      "Starting points: 20\n",
      "V = 10\n",
      "exhaustive: 7486.309999999999 \t|\t6.121338844299316 seconds\n",
      "hill_climb: 7486.309999999999 \t|\t2.189467191696167 seconds\n",
      "\n",
      "There is a huge benefit to using hillclimbing at this point!\n",
      "\n",
      "Stats for 10 cities using hill climbing:\n",
      "Starting points: 20\n",
      "Best result: 7486.3099999999995\n",
      "Worst result: 7503.099999999999\n",
      "Mean result: 7487.1494999999995\n",
      "Standard deviation: 3.7543581342220746\n",
      "\n",
      "Stats for 24 cities using hill climbing:\n",
      "Starting points: 20\n",
      "Best result: 12325.930000000002\n",
      "Worst result: 13744.199999999999\n",
      "Mean result: 13044.9875\n",
      "Standard deviation: 382.38524386409017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement the algorithm here\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "def random_start_position_result():\n",
    "    \"\"\"\n",
    "    Shuffling the list to get the random result.\n",
    "    Returns random path between cities and length of travel.\n",
    "    \n",
    "    Creates a list containing indexes representing each city from 0 to V.\n",
    "    Then using the random.shuffle to get a 'random' starting point.\n",
    "    \n",
    "        Returns:\n",
    "            random_start_list(list:int): list containing a random permutation from 0 to V.\n",
    "            length_of_travel(float): the length of the trip calculated from the permutation.\n",
    "    \"\"\"\n",
    "    random_start_list = [x for x in range(0,V)]\n",
    "    random.shuffle(random_start_list)\n",
    "\n",
    "    length_of_travel = score_calc(random_start_list, graph)\n",
    "    \n",
    "    return random_start_list, length_of_travel\n",
    "\n",
    "\n",
    "def score_calc(path, graph):\n",
    "    \"\"\"\n",
    "    Calculating the length of the trip from a given permutation.\n",
    "    \n",
    "    Takes each index from the 'path'-list and checks the distance from \n",
    "    node path[n] to path[n+1] for the whole path-list. At the end \n",
    "    the distance from the last node in path back to the first node in \n",
    "    path is added.\n",
    "    \n",
    "        param:\n",
    "            path(list:int): a given permutation of cities.\n",
    "            graph(list:list:float): list of list containing the distance between each city.\n",
    "    \n",
    "        return:\n",
    "            length_of_travel(float): Length calculated from permutation.\n",
    "    \"\"\"\n",
    "    \n",
    "    length_of_travel = 0\n",
    "    for x in range(V-1):\n",
    "        length_of_travel += graph[path[x]][path[x+1]]\n",
    "    \n",
    "    #Adding the last step which is from the last city back to the first city.\n",
    "    length_of_travel += graph[path[V-1]][path[0]]\n",
    "    \n",
    "    return length_of_travel\n",
    "    \n",
    "#amount of cities\n",
    "V = 10\n",
    "\n",
    "#Update the variable 'graph' with the new amount of cities given.\n",
    "graph = read()\n",
    "\n",
    "\n",
    "def hill_climbing(max_failures, explore_amount):\n",
    "    \"\"\"\n",
    "    Runs a hill climbing algorithm in the graph, stopping only after a \n",
    "    given breaking point is reached.\n",
    "    \n",
    "    There is room for improvement when it comes to check if each \n",
    "    permutation is actually different from each other, but the \n",
    "    possibility of each permutation used as a starting point is alike \n",
    "    is really low, and the mutation path for each permutationis also \n",
    "    random, increasing the unlikeliness.\n",
    "    \n",
    "    There is also room for improvement when it comes to the difference \n",
    "    of each permutation used. But this is something the mutations should \n",
    "    take a bit care of aswell to maintain spread.\n",
    "    \n",
    "        param:\n",
    "            max_failures(int): the max amount of rounds without any improvement.\n",
    "            explore_amount(int): the amount of starting points we want.\n",
    "            \n",
    "        return:\n",
    "            score(float): the distance calculated from traversing the found permutation\n",
    "            \n",
    "    \"\"\"\n",
    "    best_score = maxsize\n",
    "    #This will check 20 diffent starting points (exploration). Could speed things up with threading instead of loop\n",
    "    for diff_starts in range(explore_amount):\n",
    "        #Initialize amount of failures and random starting point\n",
    "        failures = 0      \n",
    "        path, score = random_start_position_result()\n",
    "        while True:\n",
    "            #Initializing two random numbers from 1 to V.\n",
    "            first_rand_index = random.randrange(1,V)\n",
    "            second_rand_index = random.randrange(1,V)\n",
    "\n",
    "            while second_rand_index == first_rand_index:\n",
    "                second_rand_index = random.randrange(1,V)\n",
    "\n",
    "            #Swapping city postition randomly but keeping only the ones which are better.\n",
    "            path_copy = path.copy()\n",
    "            path_copy[first_rand_index], path_copy[second_rand_index] = path_copy[second_rand_index], path_copy[first_rand_index]\n",
    "            if score_calc(path_copy, graph) < score_calc(path, graph):\n",
    "                path = path_copy\n",
    "                score = score_calc(path_copy, graph)\n",
    "            else:\n",
    "                failures += 1\n",
    "\n",
    "            if failures > max_failures:\n",
    "                break\n",
    "        \n",
    "        if best_score > score:\n",
    "            best_score = score\n",
    "    \n",
    "    return best_score\n",
    "\n",
    "#Testrun to compare exhaustive search to hill climbing\n",
    "def test_run_compare(v, explore_amount):\n",
    "    \"\"\"\n",
    "    Function to run tests on the v first cities comparing \n",
    "    exhaustive search with hill climb.\n",
    "\n",
    "    Distance and time prints to see results from both algorithms.\n",
    "\n",
    "\n",
    "        param:\n",
    "            v(int): amount of cities to be tested.\n",
    "            explore_amount(int): the amount of starting points we want.\n",
    "                \n",
    "    \"\"\"\n",
    "    amount_of_failures_before_break = 1000\n",
    "    V = v\n",
    "    graph = read()\n",
    "    print(\"Comparison of exhaustive search and hill climbing for the first 10 cities:\")\n",
    "    print(f\"Starting points: {explore_amount}\")\n",
    "    start_time = time.time()\n",
    "    min_dist_ex, y = exhaustive()\n",
    "    print(f\"V = {V}\")\n",
    "    print(f\"exhaustive: {min_dist_ex} \\t|\\t{time.time() - start_time} seconds\")\n",
    "    start_time = time.time()\n",
    "    result_list = []\n",
    "    for x in range(20):\n",
    "        result_list.append(hill_climbing(amount_of_failures_before_break, explore_amount))\n",
    "    print(f\"hill_climb: {min(result_list)} \\t|\\t{time.time() - start_time} seconds\")\n",
    "    print(\"\\nThere is a huge benefit to using hillclimbing at this point!\")\n",
    "\n",
    "#Testing for 10 cities with 20 starting points.\n",
    "test_run_compare(10, 20)\n",
    "\n",
    "\"\"\"\n",
    "    Prints with the best, worst, and mean result with hill climbing. \n",
    "    The standard deviation is also printed.\n",
    "    Using 1000 as the breaking point for no change in the hill climbing, \n",
    "    and the number of starting points set to 20.\n",
    "\"\"\"\n",
    "#Storing all results after 20 tries with a given failure and amount of starting points\n",
    "result_list = []\n",
    "amount_of_failures_before_break = 1000\n",
    "explore_amount = 20\n",
    "for x in range(20):\n",
    "    result_list.append(hill_climbing(amount_of_failures_before_break, explore_amount))\n",
    "\n",
    "print(\"\\nStats for 10 cities using hill climbing:\")\n",
    "print(f\"Starting points: {explore_amount}\")\n",
    "print(f\"Best result: {min(result_list)}\")\n",
    "print(f\"Worst result: {max(result_list)}\")\n",
    "print(f\"Mean result: {sum(result_list)/len(result_list)}\")\n",
    "print(f\"Standard deviation: {statistics.stdev(result_list)}\\n\")\n",
    "\n",
    "\n",
    "#amount of cities\n",
    "V = 24\n",
    "graph = read()\n",
    "\n",
    "#Storing all results after 20 tries with a given failure and amount of starting points\n",
    "result_list = []\n",
    "amount_of_failures_before_break = 3000\n",
    "explore_amount = 20\n",
    "for x in range(20):\n",
    "    result_list.append(hill_climbing(amount_of_failures_before_break, explore_amount))\n",
    "\n",
    "print(\"Stats for 24 cities using hill climbing:\")\n",
    "print(f\"Starting points: {explore_amount}\")\n",
    "print(f\"Best result: {min(result_list)}\")\n",
    "print(f\"Worst result: {max(result_list)}\")\n",
    "print(f\"Mean result: {sum(result_list)/len(result_list)}\")\n",
    "print(f\"Standard deviation: {statistics.stdev(result_list)}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm\n",
    "Next, write a genetic algorithm (GA) to solve the problem. Choose mutation and crossover operators that are appropriate for the problem (see chapter 4.5 of the Eiben and Smith textbook). Choose three different values for the population size. Define and tune other parameters yourself and make assumptions as necessary (and report them, of course).\n",
    "\n",
    "For all three variants: As with the hill climber, report best, worst, mean and standard deviation of tour length out of 20 runs of the algorithm (of the best individual of last generation). Also, find and plot the average fitness of the best fit individual in each generation (average across runs), and include a figure with all three curves in the same plot in the report. Conclude which is best in terms of tour length and number of generations of evolution\n",
    "time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stats for 10 cities using a genetic algorithm:\n",
      "Best result: 7486.3099999999995\n",
      "Worst result: 11253.660000000003\n",
      "Mean result: 7924.401724999992\n",
      "Standard deviation: 537.4571098908743\n",
      "time usage: 0.32283687591552734 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stats for 16 cities using a genetic algorithm:\n",
      "Best result: 10049.61\n",
      "Worst result: 19495.91\n",
      "Mean result: 11214.429128333286\n",
      "Standard deviation: 1299.852859346119\n",
      "time usage: 4.114753007888794 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stats for 24 cities using a genetic algorithm:\n",
      "Best result: 12287.069999999996\n",
      "Worst result: 26829.35\n",
      "Mean result: 13785.71026500074\n",
      "Standard deviation: 1831.449687101204\n",
      "time usage: 33.02506899833679 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Implement the algorithm here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_specimen_generator(amount_of_specimen):\n",
    "    \"\"\"\n",
    "    Creates random permuations from 0 to V-1, where not \n",
    "    a single specimen is completely alike.\n",
    "    \n",
    "        param:\n",
    "            amount_of_specimen(int): amount of specimen to be made.\n",
    "            \n",
    "        return:\n",
    "            list_of_spec(list:list:int): a list containing a list of indexes representing cities (a generation).\n",
    "    \"\"\"\n",
    "    list_of_spec = []\n",
    "    for i in range(amount_of_specimen):\n",
    "        rand_spec = [x for x in range(0,V)]\n",
    "        random.shuffle(rand_spec)\n",
    "        if rand_spec not in list_of_spec:\n",
    "            list_of_spec.append(rand_spec)\n",
    "\n",
    "    return list_of_spec\n",
    "\n",
    "\n",
    "def dictionary_and_sort_fitness(population, graph):\n",
    "    \"\"\"\n",
    "    Storing each population in a sorted dictionary with score as key, \n",
    "    and a list with a permutation as value.\n",
    "    \n",
    "    When picking the order crossover values I chose to pick the starting point\n",
    "    as x=2 and ending point at y=6 as this gave me consistantly better results \n",
    "    than picking this range at random. But I have added the code for random \n",
    "    values aswell, only commented out.\n",
    "    \n",
    "        param:\n",
    "            population(list:list:int): a permutation of cities\n",
    "            graph(list:list:float): the graph representing the cities and their distances to each other.\n",
    "            \n",
    "        return:\n",
    "            scores_sorted(dict:(key:float)(value:list:int)): dictionary with distance as key, and permutation as value.\n",
    "    \"\"\"\n",
    "    pop_w_score = {}\n",
    "    for spec in population:\n",
    "        pop_w_score[score_calc(spec, graph)] = spec\n",
    "    \n",
    "    scores_sorted = dict_sort_only(pop_w_score, graph)\n",
    "    \n",
    "    return scores_sorted\n",
    "\n",
    "def dict_sort_only(pop_w_score, graph):\n",
    "    \"\"\"\n",
    "    Function that sorts a dictionary.\n",
    "    \n",
    "        param:\n",
    "            pop_w_score(dict): dictionary with scores and permutations\n",
    "            graph(): graph of cities and their distances\n",
    "        \n",
    "        return:\n",
    "            scores_sorted():\n",
    "    \"\"\"\n",
    "    scores_sorted = {}\n",
    "    for key in sorted(pop_w_score, reverse=False):\n",
    "        scores_sorted[key] = pop_w_score[key]\n",
    "    return scores_sorted\n",
    "\n",
    "def genetic(pop_size, pop, graph, start=False):\n",
    "    \"\"\"\n",
    "    Runs a genetic algorithm with a given start population.\n",
    "    \n",
    "    Using both mutation and order crossover to achieve change (evolution).\n",
    "    \n",
    "        param:\n",
    "            pop_size(int): size of the population.\n",
    "            pop(): list of permutations (solutions).\n",
    "            graph(): cities and the distances\n",
    "            start(boolean)=False: True if the function is run for the first time\n",
    "        \n",
    "        returns:\n",
    "            new_pop(dict): dictionary containing city permutations and their scores\n",
    "    \"\"\"\n",
    "    #Creating a new dictionary if no dictionary is given\n",
    "    if start == True:\n",
    "        pop_w_score = dictionary_and_sort_fitness(pop, graph).copy()\n",
    "    else:\n",
    "        pop_w_score = pop.copy()\n",
    "   \n",
    "    #Order crossover\n",
    "    x = random.randrange(1,int(V/2)) #start index of subset\n",
    "    y = random.randrange(int(V/2),V-1) #end index of subset\n",
    "    #x = 2\n",
    "    #y = 6\n",
    "    \n",
    "    pop_list = list(pop_w_score.values())\n",
    "    \n",
    "    child_list = [] #All new offspring stored in a list\n",
    "\n",
    "    #picking the two and two best specimen to create two and two offspring\n",
    "    for parentid in range(0, pop_size, 2):\n",
    "        #Creating two children-lists with size of V containing None\n",
    "        first_child = [None for x in range(V)]\n",
    "        second_child = [None for x in range(V)]\n",
    "        #Children given genes from parents. Taken from the range x and y in parents\n",
    "        first_child[x:y] = list(pop_list[parentid][x:y])\n",
    "        second_child[x:y] = list(pop_list[parentid+1][x:y])        \n",
    "        \n",
    "        #Order crossover\n",
    "        #Mutate the child\n",
    "        #Store all offspring in list\n",
    "        first_child = order_crossover(pop_list[parentid+1], y+1, first_child)\n",
    "        first_child_mutated = mutate(first_child).copy()\n",
    "        child_list.append(first_child)\n",
    "        child_list.append(first_child_mutated)\n",
    "        second_child = order_crossover(pop_list[parentid], y+1, second_child)\n",
    "        second_child_mutated = mutate(second_child).copy()\n",
    "        child_list.append(second_child)\n",
    "        child_list.append(second_child_mutated)\n",
    "\n",
    "        #Creating a dict of each genotype with its score/fitness\n",
    "        offspring_w_score = dictionary_and_sort_fitness(child_list, graph)\n",
    "        \n",
    "    #Creating the new population\n",
    "    new_pop = next_population(pop_w_score, offspring_w_score, pop_size).copy()\n",
    "    new_pop = dict_sort_only(new_pop, graph).copy()\n",
    "\n",
    "    return new_pop\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "def next_population(old_pop, offspring, pop_size):\n",
    "    \"\"\"\n",
    "    Creates a new dict containing the new population generation.\n",
    "    \n",
    "    Using a learning rate of 0.08 to find the right specimen.\n",
    "    The offspring and old population has been sorted after their fitness.\n",
    "    Using both offspring and old population when picking the next generation \n",
    "    gave a better result than just using the offspring alone.\n",
    "\n",
    "    \n",
    "        param:\n",
    "            old_pop(dict): dictionary containing info about the generation\n",
    "            offspring(dict): dictionary containing info about the children of the generation\n",
    "            pop_size(int): size of population that we want to achieve\n",
    "        \n",
    "        return:\n",
    "            new_population(dict): dictionary containing info about the new generation\n",
    "    \"\"\"\n",
    "    new_population = {}\n",
    "\n",
    "    tot_score = sum(offspring.keys())+sum(old_pop.keys())\n",
    "    tot_len = len(offspring.keys())+len(old_pop.keys())\n",
    "    \n",
    "\n",
    "    #Making a new dict storing both old and new specimen\n",
    "    main_dict = concat_dict(old_pop, offspring).copy()\n",
    "    \n",
    "    \n",
    "    #Ranking fitness\n",
    "    main_dict = dict_sort_only(main_dict, graph).copy()\n",
    "    \n",
    "    #THIS IS IF YOU DO NOT WANT TO USE A LEARNING RATE AND ONLY TO LOOK AT THE BEST OFFSPRING\n",
    "    #Take the n'th best from both old_pop and offspring \n",
    "    for i, x in enumerate(main_dict.items()):\n",
    "        new_population[x[0]] = x[1]\n",
    "        if i == pop_size:\n",
    "            break\n",
    "    \n",
    "    return new_population\n",
    "\n",
    "    \n",
    "def concat_dict(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Takes to dictionaries and concatinate them.\n",
    "    \n",
    "        param:\n",
    "            dict1(dict): dictionary with keys and values\n",
    "            dict2(dict): dictionary with keys and values\n",
    "            \n",
    "        return:\n",
    "            new_dict(dict): new dictionary containing the keys and values of both dict1 and dict2.\n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for x in dict1.items():\n",
    "        new_dict[x[0]] = x[1]\n",
    "        \n",
    "    for x in dict2.items():\n",
    "        new_dict[x[0]] = x[1]\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def mutate(child):\n",
    "    \"\"\"\n",
    "    Mutates the permutation given by swapping places between two 'genes' by index.\n",
    "    \n",
    "    \n",
    "        param:\n",
    "            child(list:int): list that represents order of cities by index. A permutation\n",
    "    \n",
    "        returns:\n",
    "            child (list:int) a mutated list that represents order of cities by index. A permutation\n",
    "    \"\"\"\n",
    "    #Random genes to swap\n",
    "    x = random.randrange(0, V) #Letting the first city be unchanged.\n",
    "    y = random.randrange(0, V) #Letting the first city be unchanged.\n",
    "    \n",
    "    #Checks if x != y\n",
    "    while x == y:\n",
    "        y = random.randrange(0,V)\n",
    "        \n",
    "    #Swapping genes as a form of mutation to maintain diversity\n",
    "    child[x], child[y] = child[y], child[x]\n",
    "    \n",
    "    return child\n",
    "\n",
    "def order_crossover(p2, index, child):\n",
    "    \"\"\"\n",
    "    Making a child out of given parent and index situation with order_crossover().\n",
    "    \n",
    "    Double while-loop to do order crossover. \n",
    "    Takes one parent, using a random sublist of genes from p1, insert in child.\n",
    "    This step has already been done in genetic(). \n",
    "    The genes already placed in child is from p1.\n",
    "    Placing p2 rest in right order of p2 in child.\n",
    "    Variable counter keeps track of index position in child.\n",
    "    \n",
    "        param:\n",
    "            p2(list:int): list representing parent 2 containing indexes.\n",
    "            index(int): index to tell where we should start the order crossover from.\n",
    "            child(list:int): list representing start of child containing indexes given from parent 1\n",
    "    \n",
    "        return: \n",
    "            child (list:int): list representing the child of p1 and p2.\n",
    "    \"\"\"\n",
    "    counter = index\n",
    "    while None in child:\n",
    "        if index < V:\n",
    "            if p2[index] not in child:\n",
    "                while child[counter] != None:\n",
    "                    counter += 1\n",
    "                    if counter == V:\n",
    "                        counter = 0\n",
    "                child[counter] = p2[index]\n",
    "            else:\n",
    "                index += 1\n",
    "        else:\n",
    "            index = 0\n",
    "    return child\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stat_print(algo_time, best, worst, mean, st_dev):\n",
    "    \"\"\"\n",
    "    Function to print test results.\n",
    "    \n",
    "    Prints stats for best, worst, and mean result.\n",
    "    Also standard deviation and time usage.\n",
    "    \n",
    "        param:\n",
    "            algo_time(float): algorithm's tracked time.\n",
    "            best(float): best result.\n",
    "            worst(float): worst result.\n",
    "            mean(float): mean result.\n",
    "            st_dev(float): standard deviation.\n",
    "    \"\"\"\n",
    "    print(f\"Stats for {V} cities using a genetic algorithm:\")\n",
    "    print(f\"Best result: {best}\")\n",
    "    print(f\"Worst result: {worst}\")\n",
    "    print(f\"Mean result: {mean}\")\n",
    "    print(f\"Standard deviation: {st_dev}\")\n",
    "    print(f\"time usage: {algo_time} seconds\")\n",
    "\n",
    "def plotting(all_min):\n",
    "    \"\"\"\n",
    "    For plotting the average fitness for each generation.\n",
    "    \n",
    "        param:\n",
    "            all_min(list:float): average fitness for each generation.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(all_min)\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.title(f\"{V} cities and {cap} generations\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#THIS IS THE TESTING GROUND. THIS IS WHERE THE FUNCTION CALLS ARE PLACED. SORRY FOR THE REPEATED CODE!\n",
    "#IT'S THE SAME CODE REPEATED 3 TIMES BUT WITH V=10 cap=60, V=16 cap=300, and V=24 cap=800\n",
    "print()\n",
    "V = 10\n",
    "graph = read()\n",
    "population_size = V\n",
    "#generation amount\n",
    "cap = 60\n",
    "result_list = []\n",
    "average_fitness_1 = []\n",
    "average_fitness_1_last = []\n",
    "time_start = time.time()\n",
    "for round_test in range(20):\n",
    "    pop = genetic(population_size,random_specimen_generator(population_size), graph, start=True).copy()\n",
    "    local_result = []\n",
    "    for x in range(cap):\n",
    "        pop = genetic(population_size, pop, graph, start=False).copy()\n",
    "        result_list.append(list(pop.keys())[0])\n",
    "        local_result.append(list(pop.keys())[0])\n",
    "        average_fitness_1.append(sum(list(pop.keys()))/len(list(pop.keys())))\n",
    "        \n",
    "    average_fitness_1_last.append(sum(local_result)/len(local_result))\n",
    "    \n",
    "algo_time = time.time() - time_start\n",
    "print()\n",
    "#print(pop)\n",
    "best = min(result_list)\n",
    "worst = max(result_list)\n",
    "mean = sum(result_list)/len(result_list)\n",
    "st_dev = statistics.stdev(result_list)\n",
    "\n",
    "\n",
    "stat_print(algo_time, best, worst, mean, st_dev)\n",
    "plotting(average_fitness_1)\n",
    "\n",
    "\"\"\"--------------------------------------------------------------\"\"\"\n",
    "print()\n",
    "V = 16\n",
    "graph = read()\n",
    "population_size = V\n",
    "cap = 300\n",
    "result_list = []\n",
    "average_fitness_2 = []\n",
    "average_fitness_2_last = []\n",
    "time_start = time.time()\n",
    "for round_test in range(20):\n",
    "    pop = genetic(population_size,random_specimen_generator(population_size), graph, start=True).copy()\n",
    "    local_result = []\n",
    "    for x in range(cap):\n",
    "        pop = genetic(population_size, pop, graph, start=False).copy()\n",
    "        result_list.append(list(pop.keys())[0])\n",
    "        local_result.append(list(pop.keys())[0])\n",
    "        average_fitness_2.append(sum(list(pop.keys()))/len(list(pop.keys())))\n",
    "        \n",
    "    average_fitness_2_last.append(sum(local_result)/len(local_result))\n",
    "\n",
    "algo_time = time.time() - time_start\n",
    "print()\n",
    "best = min(result_list)\n",
    "worst = max(result_list)\n",
    "mean = sum(result_list)/len(result_list)\n",
    "st_dev = statistics.stdev(result_list)\n",
    "\n",
    "stat_print(algo_time, best, worst, mean, st_dev)\n",
    "plotting(average_fitness_2)\n",
    "\n",
    "\"\"\"--------------------------------------------------------------\"\"\"\n",
    "print()\n",
    "V = 24\n",
    "graph = read()\n",
    "population_size = V\n",
    "cap = 1000\n",
    "result_list = []\n",
    "average_fitness_3 = []\n",
    "average_fitness_3_last = []\n",
    "time_start = time.time()\n",
    "for round_test in range(20):\n",
    "    pop = genetic(population_size,random_specimen_generator(population_size), graph, start=True).copy()\n",
    "    local_result = []\n",
    "    for x in range(cap):\n",
    "        pop = genetic(population_size, pop, graph, start=False).copy()\n",
    "        result_list.append(list(pop.keys())[0])\n",
    "        local_result.append(list(pop.keys())[0])\n",
    "        average_fitness_3.append(sum(list(pop.keys()))/len(list(pop.keys())))\n",
    "        \n",
    "    average_fitness_3_last.append(sum(local_result)/len(local_result))\n",
    "\n",
    "#Calculating results\n",
    "algo_time = time.time() - time_start\n",
    "print()\n",
    "best = min(result_list)\n",
    "worst = max(result_list)\n",
    "mean = sum(result_list)/len(result_list)\n",
    "st_dev = statistics.stdev(result_list)\n",
    "\n",
    "stat_print(algo_time, best, worst, mean, st_dev)\n",
    "plotting(average_fitness_3)\n",
    "\n",
    "#Plotting three averages in one plot\n",
    "plt.figure()\n",
    "plt.plot(average_fitness_1_last, color='red')\n",
    "plt.plot(average_fitness_2_last, color='blue')\n",
    "plt.plot(average_fitness_3_last, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the first 10 cities, did your GA find the shortest tour (as found by the exhaustive search)? Did it come close? \n",
    "\n",
    "For both 10 and 24 cities: How did the running time of your GA compare to that of the exhaustive search? \n",
    "\n",
    "How many tours were inspected by your GA as compared to by the exhaustive search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAfter changing the 'learning_rate' quite a bit I have come closer and closer to the global optimum.\\nI even got the real close to the global optimum with a test-run giving the score of 7486.31 (rounded) with V=10. \\nA result thats real close to the one the Exhaustive Algorithm gave.\\n\\nHere is a print of one of the more successful run, with a generation-span of 20, population size of 10, \\nand learning rate of 0.08 with an increase of +0.0001 for each generation where the learning_rate is to great:\\n\\n{7486.3099999999995: [1, 9, 4, 5, 2, 6, 8, 3, 7, 0], 7549.16: [1, 4, 9, 5, 2, 6, 8, 3, 7, 0], \\n    7887.03: [1, 9, 4, 5, 8, 6, 2, 3, 7, 0], 8039.1900000000005: [1, 5, 4, 9, 2, 6, 8, 3, 7, 0], \\n    8182.92: [9, 4, 5, 1, 2, 6, 8, 7, 3, 0], 8398.259999999998: [9, 4, 5, 1, 8, 6, 2, 3, 7, 0], \\n    8456.11: [1, 4, 9, 5, 2, 6, 8, 3, 0, 7], 8472.380000000001: [1, 9, 4, 5, 3, 6, 2, 8, 7, 0], \\n    8500.720000000001: [5, 1, 9, 4, 2, 3, 8, 6, 7, 0], 8663.73: [9, 1, 5, 4, 2, 6, 8, 3, 7, 0]}\\n    \\nlowest distance = 7486.31(rounded)\\n\\n\\nThe best I got with the Genetic algorithm is 12740.410000000002 after many tries.\\n\\n\\nI have included two different approaches when it comes to choosing what specimen gets to be part of the new \\ngeneration. One total elitist where the best of each generation gets picked every time, and another where I have \\ntried to include some variation of the 'solidification' of iron from a fluid to a solid state. The learning_rate \\nresets every generation.\\n\\nBy looking at the plot over average fitness by each generation, it looks like the genetic need more time \\n(more than 20 generations) to find the global optimum when the amount of cities rises. The graph has not flattened \\nand therefore it may be a signs of a better potential global optimum.\\n\\n\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer\n",
    "\"\"\"\n",
    "After changing the 'learning_rate' quite a bit I have come closer and closer to the global optimum.\n",
    "I even got the real close to the global optimum with a test-run giving the score of 7486.31 (rounded) with V=10. \n",
    "A result that's real close to the one the Exhaustive Algorithm gave.\n",
    "\n",
    "\n",
    "The best I got with the Genetic algorithm is 12287.069999999998 after many tries. (800 gen, 20 runs)\n",
    "800 is probably a lot more than needed, but I wanted to be sure that there is no room for improvement later down \n",
    "the line with some random mutation. Also, I tried to look at the graph of one run to see where it started to flatten. \n",
    "I also wanted the answer to be consistent.\n",
    "\n",
    "\n",
    "I have included two different approaches when it comes to choosing what specimen gets to be part of the new \n",
    "generation. One total elitist where the best of each generation gets picked every time, and another where I have \n",
    "tried to include some variation of the 'solidification' of iron from a fluid to a solid state, just reversed. The learning_rate \n",
    "resets every generation. Funnny enough this approach gave me a result really close to the best result with a score of \n",
    "12325.93.\n",
    "\n",
    "By looking at the plot over average fitness by each generation, it looks like the genetic need more time \n",
    "(more than 20 generations) to find the global optimum when the number of cities rises. The graph has not flattened \n",
    "and therefore it may be a signs of a better potential global optimum. Sometimes my GA performs better than my hillclimb, \n",
    "and sometimes it does not. This could be because the mutations of my GA in one run is really good, and other times really \n",
    "poor.\n",
    "\n",
    "To improve my GA I could've probably used another crossover or other forms of mutation that's more likely to \n",
    "give a more consistent answer for 24 cities, since this is the one where the answer changes from each run, unlike for \n",
    "10 (at 7486.3099999999995) and 16 (at 10049.61) cities which are quite stable (under testing that is).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Algorithm (IN4050 only)\n",
    "### Lamarckian\n",
    "Lamarck, 1809: Traits acquired in parents’ lifetimes can be inherited by offspring. In general the algorithms are referred to as Lamarckian if the result of the local search stage replaces the individual in the population.\n",
    "### Baldwinian\n",
    "Baldwin effect suggests a mechanism whereby evolutionary progress can be guided towards favourable adaptation without the changes in individual's fitness arising from learning or development being reflected in changed genetic characteristics. In general the algorithms are referred to as Baldwinian if the original member is kept, but has as its fitness the value belonging to the outcome of the local search process.\n",
    "\n",
    "\n",
    "(See chapter 10 and 10.2.1 from Eiben and Smith textbook for more details. It will also be lectured in Lecure 4)\n",
    "\n",
    "### Task\n",
    "Implement a hybrid algorithm to solve the TSP: Couple your GA and hill climber by running the hill climber a number of iterations on each individual in the population as part of the evaluation. Test both Lamarckian and Baldwinian learning models and report the results of both variants in the same way as with the pure GA (min,\n",
    "max, mean and standard deviation of the end result and an averaged generational plot). How do the results compare to that of the pure GA, considering the number of evaluations done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement algorithm here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
